# 伪分布

## 环境准备
　　
此处准备的环境是Virtual Box虚拟机下的Ubuntu14.04 64位系统，Hadoop版本为Hadoop2.6.0。装好Hadoop运行的基础Linux环境后，还需要做以下准备：

　- 创建hadoop用户；
　- 更新apt；
　- 配置SSH免密登陆；
　- 安装配置Java环境。

### 创建hadoop用户
　　如果安装系统时配置的并非是“hadoop”用户，就需要新增加一个“hadoop”用户。

`sudo useradd -m hadoop -s /bin/bash`
　　该命令创建新的`hadoop`用户，并指定 `/bin/bash` 作为其shell。

　　如需更改hadoop用户密码，可通过如下命令进行：

 `sudo passwd hadoop`
　　

　　同样，为避免后期安装过程中的用户权限问题，可直接给“hadoop”用户添加上管理员权限：

 `sudo adduser hadoop sudo`
　　之后，需切换到hadoop用户下进行下面操作。

### 更新apt

　　切换到hadoop用户之后，需要先更新一下apt，后续需要通过apt安装其他软件，直接在命令行安装会方便很多，如果没有更新，一些软件可能安装不了。可参考以下命令进行更新：

 `$ sudo apt-get update`
　　Linux 的编辑工具，当然非 vim 莫属了，先装上 vim 后期改参数配置文件时用的到。

 `$ sudo apt-get install vim`
　　遇到命令行的 [ yes/no] 或者 [Y/N] 选项，直接yes进行安装。

### 配置SSH免密登陆
　　
 `单点/集群`都需要安装SSH。

 1. 一方面是远程登陆，可一再本机通过SSH直接连接虚拟机的系统，这样也便于后期在Windows环境下使用 Eclipse 进行配置开发 MapReduce 程序；
 2. 另一方面，在配置Hadoop集群时，集群工作过程中主机和从机、从机和从机之间都通过SSH进行授权登陆工作通信。Ubuntu系统默认已经安装了SSH Client，需要额外安装SSH Server。

`$ sudo apt-get install openssh-server`
　　首次登陆SSH会有首次登陆提示，键入yes，按提示输入hadoop用户密码即可登陆。

- 配置免密登陆。
    1. 一方面，通过ssh登陆时比较方便，不需重新输入密码；
    2. 另一方面，在集群方式工作时，主机与从机通信过程或从机与从机之间进行文件备份时是需要越过密码验证这一环节的，所以需要提前生成公钥，在集群工作时，可以直接自动登陆。

    ```sh
    cd ~/.ssh                               #若无此目录，请先进行一次ssh 登陆
    ssh-keygen -t rsa                       #会有很多提示，全部回车即可
    cat ./id_rsa.pub >> ./authorized_keys   #将公钥文件加入授权
    ```

>再次通过 ssh 登陆就不需要输入密码了。

### 安装配置Java环境
　　
    Java环境，Oracle JDK 和 OpenJDK都可以，此处直接通过命令安装OpenJDK1.7(其中包含 jre 和 jdk)：

   `sudo apt-get install openjdk-7-jre openjdk-7-jdk`

- 配置环境变量：

　　安装好JDK后，需要配置Java环境变量，通过以下命令寻找Java安装路径：

 `dpkg -L openjdk-7-jdk | grep '/bin/javac'`
　　
 该命令会输出一个路径，除去路径末尾的 “/bin/javac”，剩下的就是JDK的安装路径了。

- 在.bashrc文件中配置环境变量：

 `echo "export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64" >> .bashrc`
 需要在`.bashrc`文件中添加如下环境变量：

 生效并检验环境变量配置是否正确：

 `source ./.bashrc                  #生效环境变量`
 `echo $JAVA_HOME                   #查看环境变量`
 `java -version`
 `$JAVA_HOME/bin/java -version      #验证与java -version 输出一致`

 > Java环境安装配置完成。

### 安装Hadoop

 通过`http://mirrors.cnnic.cn/apache/hadoop/common/`可下载Hadoop稳定版 `hadoop-2.x.y.tar.gz` 文件都是编译好的，

- 通过验证文件的md5值去检验文件的完整性：

 `$ cat ./hadoop-2.6.0.tar.gz.mds | grep 'MD5'`
 `md5sum ./hadoop-2.6.0.tar.gz | tr 'a-z' 'A-Z'`

> 文件验证无误，将文件解压到安装目录：

```sh
cd /usr/lcoal                              #切换到压缩文件所在目录
sudo tar -xvf ./hadoop-2.6.0.tar.gz ./     #解压文件
sudo mv ./hadoop-2.6.0 ./hadoop            #将文件名改为较容易辨认的
chown -R hadoop ./hadoop                   #修改文件权限
```

- 在`.bashrc`文件中配置hadoop相关环境变量：

```sh
echo "
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin" >> .bashrc
```

 生效环境变量，并验证Hadoop安装成功。
  
  `$ source ~/.bashrc`
  `$ hadoop version`

> 不能配置，可以采用`ln 链接`