# 四、配置所有Hadoop节点

需要配置以下几个文件

`core-site.xmlcore-size.xml`文件包含了NameNode主机地址以及其监听`RPC`端口等信息（NameNode默认使用的RPC端口为`8020`）

1. 对于分布式环境，每个节点都需要设置`NameNode`主机地址，其简要的配置内容如下所示：

`su - hadoop`

`vim /usr/local/hadoop/etc/hadoop/core-site.xml`

添加以下配置：

```xml
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://master:8020</value>
        <final>true</final>
        </property>
</configuration>
```

`hdfs-site.xmlhdfs-site.xml`主要用于配置HDFS相关的属性

例如**复制因子**（即数据块的副本数），matser和dn用于存储数据的目录等。

> 数据块的副本数对于分布式的Hadoop应该为`3`，这里我设置为`2`，为了减少磁盘使用。

而`NN`和DN用于存储数据的目录为前面的步骤中专门为其创建的路径。

另外，前面的步骤中也为SNN创建了相关的目录，这里也一并配置为启用状态。

`su - hadoop`
`vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml`

```xml
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>2</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:///data/hadoop/hdfs/nn</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:///data/hadoop/hdfs/dn</value>
        </property>
       <property>
                <name>fs.checkpoint.dir</name>
                <value>file:///data/hadoop/hdfs/snn</value>
        </property>
        <property>
                <name>fs.checkpoint.edits.dir</name>
                <value>file:///data/hadoop/hdfs/snn</value>
        </property>
        <property>
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
</configuration>
```

`mapred-site.xmlmapred-site.xml`文件用于配置集群的`MapReduce framework`

此处应该指定使用`yarn`，另外的可用值还有`local`和`classic`。

3. `mapred-site.xml`默认不存在，但有模版文件`mapred-site.xml.template`，只需要将其复制为`mapred-site.xml`即可。

`su - hadoop`
`cp -fr /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml`

`vim /usr/local/hadoop/etc/hadoop/mapred-site.xml`

```xml
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
</configuration>
```

`yarn-site.xmlyarn-site.xml`用于配置YARN进程及YARN的相关属性，首先需要指定`ResourceManager`守护进程的主机和监听的端口（这里`ResourceManager`准备安装在NameNode节点）；
其次需要指定`ResourceMnager`使用的`scheduler`，以及`NodeManager`的辅助服务。一个简要的配置示例如下所示：

`vim /usr/local/hadoop/etc/hadoop/yarn-site.xml`

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>master:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>master:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>master:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address</name>
        <value>master:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:8088</value>
    </property>
    <property><name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.auxservices.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
    </property>
</configuration>
```

`hadoop-env.sh`和`yarn-env.sh`

   1. Hadoop的各个守护进程依赖于`JAVA_HOME`环境变量，如果有类似于前面步骤中通过`/etc/profile.d/java.sh`全局配置定义的`JAVA_HOME`变量即可正常使用。

   2. 不过，如果想为`Hadoop`定义依赖到特定`JAVA`环境，也可以编辑这两个脚本文件，为其`JAVA_HOME`取消注释并配置合适的值即可。
   3. 此外，Hadoop大多数守护进程默认使用的堆大小为`1GB`，但现实应用中，可能需要对其各类进程的堆内存大小做出调整，这只需要编辑此两者文件中相关环境变量值即可
      例如`HADOOP_HEAPSIZE、HADOOP_JOB_HISTORY_HEADPSIZE、JAVA_HEAP_SIZE和YARN_HEAP_SIZE`等。
   4. `slaves`文件`slaves`文件存储于了当前集群的所有`slave`节点的列表，默认值为`localhost`。

4. 这里打算在三个节点都安装DataNode，所以都添加进去即可。

`su - hadoop`
`vim /usr/local/hadoop/etc/hadoop/slaves`

```
hadoop-matser
hadoop-dn-02
hadoop-dn-01
```

到目前为止，第一个节点（Master）已经配置好了。

在hadoop集群中，所有节点的配置都应该是一样的，前面也为`slaves`节点创建了Hadoop用户、数据目录以及日志目录等配置。

5. 接下来就是把`Master`节点的配置文件都同步到所有`Slaves`即可。

`su - hadoop`

```bash
scp /usr/local/hadoop/etc/hadoop/* hadoop@hadoop-dn-02:/usr/local/hadoop/etc/hadoop/
scp /usr/local/hadoop/etc/hadoop/* hadoop@hadoop-dn-01:/usr/local/hadoop/etc/hadoop/
```